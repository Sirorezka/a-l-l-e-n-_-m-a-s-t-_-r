{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import ipyth_utils\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import time\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#urls  to get toppics\n",
    "ck12_url_topic = ['https://www.ck12.org/earth-science/', 'http://www.ck12.org/life-science/', \n",
    "                  'http://www.ck12.org/physical-science/', 'http://www.ck12.org/biology/', \n",
    "                  'http://www.ck12.org/chemistry/', 'http://www.ck12.org/physics/',\n",
    "                  'http://www.ck12.org/astronomy/','http://www.ck12.org/history/',\n",
    "                  ]\n",
    "wiki_docs_dir = '../data/wiki_data'\n",
    "\n",
    "def get_wiki_docs():\n",
    "    # get keywords \n",
    "    ck12_keywords = set()\n",
    "    for url_topic in ck12_url_topic:\n",
    "        keywords= ipyth_utils.get_keyword_from_url_topic(url_topic)\n",
    "        for kw in keywords:\n",
    "            ck12_keywords.add(kw)\n",
    "    \n",
    "    #get and save wiki docs\n",
    "    utils.get_save_wiki_docs(ck12_keywords, wiki_docs_dir)\n",
    "\n",
    "\n",
    "class ck12_predict_cl():\n",
    "    def __init__ (self):\n",
    "        self.docs_tf = dict()\n",
    "        self.words_idf = dict()\n",
    "        self.ngram = -1\n",
    "        #index docs\n",
    "        pass\n",
    "    \n",
    "    def tf_idf_dict (self, n_gram):\n",
    "        self.docs_tf, self.words_idf = ipyth_utils.get_docstf_idf(wiki_docs_dir,n_gram)\n",
    "        self.max_n_gram = n_gram\n",
    "        pass\n",
    "    \n",
    "    def similar_score(self, data, docs_per_q, n_gram):\n",
    "        res = []\n",
    "        doc_score = [[\"A\",\"B\",\"C\",\"D\"]]\n",
    "        for index, row in data.iterrows():\n",
    "            #get answers words\n",
    "            w_A = set(ipyth_utils.tokenize(row['answerA'],n_gram))\n",
    "            w_B = set(ipyth_utils.tokenize(row['answerB'],n_gram))\n",
    "            w_C = set(ipyth_utils.tokenize(row['answerC'],n_gram))\n",
    "            w_D = set(ipyth_utils.tokenize(row['answerD'],n_gram))\n",
    "\n",
    "            sc_A = 0\n",
    "            sc_B = 0\n",
    "            sc_C = 0\n",
    "            sc_D = 0\n",
    "\n",
    "            q = row['question']\n",
    "\n",
    "            for d in list(zip(*ipyth_utils.get_docs_importance_for_question(q, self.docs_tf, self.words_idf, n_gram = n_gram, max_docs = docs_per_q)))[0]:\n",
    "                for w in w_A:\n",
    "                    if w in self.docs_tf[d]:\n",
    "                        sc_A += 1. * self.docs_tf[d][w] * self.words_idf[w]\n",
    "                for w in w_B:\n",
    "                    if w in self.docs_tf[d]:\n",
    "                        sc_B += 1. * self.docs_tf[d][w] * self.words_idf[w]\n",
    "                for w in w_C:\n",
    "                    if w in self.docs_tf[d]:\n",
    "                        sc_C += 1. * self.docs_tf[d][w] * self.words_idf[w]\n",
    "                for w in w_D:\n",
    "                    if w in self.docs_tf[d]:\n",
    "                        sc_D += 1. * self.docs_tf[d][w] * self.words_idf[w]\n",
    "\n",
    "            res.append(['A','B','C','D'][np.argmax([sc_A, sc_B, sc_C, sc_D])])\n",
    "            doc_score.append([sc_A, sc_B, sc_C, sc_D])\n",
    "        return res, doc_score\n",
    "\n",
    "\n",
    "def evaluate_score (y_model, y_real):\n",
    "    model_score = sum(y_model==y_real)/len(y_real)\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Input parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "fname_str = 'joined_set.tsv'\n",
    "docs_per_q = 10\n",
    "get_wiki_data = 0  # put 1 if you want to download wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: reading csv\n",
      "Data collected\n"
     ]
    }
   ],
   "source": [
    "## READING THE DATA\n",
    "\n",
    "if get_wiki_data:\n",
    "    print(\"run: get wiki docs\")\n",
    "    get_wiki_docs()\n",
    "    \n",
    "print(\"run: reading csv\")    \n",
    "#read data\n",
    "data = pd.read_csv('../data/' + fname_str, sep = '\\t')\n",
    "\n",
    "print(\"Data collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TF-idf model\n",
      "running tf_idf\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "tf-idf collected\n",
      "elapsed time:  8.65\n"
     ]
    }
   ],
   "source": [
    "## BUILDING TF-IDF MODEL\n",
    "\n",
    "print(\"Building TF-idf model\")\n",
    "start_time = time.time()\n",
    "ck12_prediction = ck12_predict_cl ()\n",
    "ck12_prediction.tf_idf_dict(n_gram = 3)\n",
    "print (\"tf-idf collected\")\n",
    "print (\"elapsed time: \",round((time.time()-start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['head', 'vision', 'nearby', 'east northeast', 'government', 'three people', 'km', 'earthquake papua', 'magnitude', 'ten', 'two hotels', 'quake twenty', 'magnitude earthquake', 'official world', 'observatory', 'peninsula official', 'official officials', 'occurred', 'totally', 'world vision', 'external', 'km mi', 'four', 'hotels collapsed', 'occurring', 'references external', 'mi west', 'northwest', 'manokwari pulled', 'bird head', 'magnitude occurring', 'people staying', 'buildings totally', 'mutiara hotel', 'manokwari km', 'epicenter', 'ten buildings', 'see also', 'utc', 'guinea', 'earthquake references', 'west papua', 'papua earthquake', 'local', 'papua province', 'peninsula', 'vision said', 'rubble', 'january local', 'magnitude january', 'several', 'guinea darwin', 'destroyed including', 'earthquake', 'papua new', 'injuring dozens', 'darwin', 'felt', 'west northwest', 'least four', 'time january', 'earth observatory', 'dozens', 'collapsed', 'earthquake occurred', 'magnitude one', 'west', 'northwest manokwari', 'kilometres mi', 'external links', 'twenty three', 'indonesia nasa', 'aftershocks', 'house', 'collapsed quake', 'links earthquake', 'officials said', 'another', 'northeast sorong', 'earth', 'people epicenter', 'australia see', 'head peninsula', 'mi east', 'references', 'nasa', 'links', 'nearby papua', 'manokwari', 'rubble taken', 'january utc', 'including', 'staying', 'time killing', 'one magnitude', 'hospital', 'said', 'sorong indonesia', 'totally destroyed', 'pulled', 'four injuring', 'indonesia west', 'hospital two', 'mutiara', 'occurred moment', 'least', 'papua', 'another magnitude', 'one', 'mi', 'hotel', 'new', 'quake', 'moment magnitude', 'province', 'taken', 'darwin australia', 'sorong', 'papua indonesia', 'epicenter kilometres', 'utc another', 'kilometres', 'alive', 'official', 'city', 'twenty', 'two', 'said three', 'staying mutiara', 'several hotels', 'australia', 'province bird', 'people', 'injuring', 'three', 'new guinea', 'killing', 'felt nearby', 'local time', 'also west', 'also felt', 'hotels', 'dozens people', 'occurring local', 'hotel city', 'officials', 'buildings', 'bird', 'killing least', 'destroyed', 'said ten', 'indonesia', 'aftershocks magnitude', 'northeast', 'hotels house', 'taken hospital', 'house government', 'time', 'east', 'including several', 'government official', 'world', 'see', 'moment', 'earthquake also', 'also', 'nasa earth', 'january', 'alive rubble', 'three aftershocks', 'pulled alive', 'city manokwari'])\n"
     ]
    }
   ],
   "source": [
    "## Checking that we have correct ngrams for some word in the data\n",
    "#print (ck12_prediction.docs_tf['21st_century_tsunami.txt'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: predicting data\n",
      "elapsed time:  1.71\n",
      "finished predicting probabilities\n"
     ]
    }
   ],
   "source": [
    "## PREDICTING DATA\n",
    "\n",
    "#predict\n",
    "print(\"run: predicting data\")\n",
    "start_time = time.time()\n",
    "res, prob_scores = ck12_prediction.similar_score(data, docs_per_q = 10, n_gram = 2)\n",
    "print (\"elapsed time: \",round((time.time()-start_time)/60,2))\n",
    "print (\"finished predicting probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3752\n"
     ]
    }
   ],
   "source": [
    "## EVALUATING SCORES\n",
    "\n",
    "y = data.iloc[0:2500,6]\n",
    "y_pred = res[0:2500]\n",
    "print (evaluate_score (y_pred,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running parameter query test accross the data // <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generating dictionary - probably too extensive\n",
    "\n",
    "#ck12_prediction = ck12_predict_cl ()\n",
    "#ck12_prediction.tf_idf_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Should be done in parallel\n",
    "\n",
    "# MAKE RUN ACROSS PARAMETERS\n",
    "par_arange = np.arange(1,5,1)\n",
    "\n",
    "scor_li = []\n",
    "for par_iter in par_arange:\n",
    "    print(\"run: predicting data\")\n",
    "    res, prob_scores = ck12_prediction.similar_score(data, docs_per_q = 10, n_gram = par_iter)\n",
    "    prob_scores = np.array(prob_scores).flatten()\n",
    "    prob_scores = np.resize (prob_scores,(len(prob_scores)/4,4))\n",
    "    print (\"finished preciting probabilities:\")\n",
    "    print (prob_scores[0:2,:])\n",
    "\n",
    "    y = data.iloc[0:2500,6]\n",
    "    y_pred = res[0:2500]\n",
    "    print (\"parameter: \",par_iter, \" : \",evaluate_score (y_pred,y))\n",
    "    scor_li.append(evaluate_score (y_pred,y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot (par_arange,scor_li)\n",
    "plt.title (\"Number of similar docs to look for vs Model perfomance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Optmal number of docs is 15, however it's good to try small too\n",
    "\n",
    "res, prob_scores = ck12_prediction.similar_score(data, 15)\n",
    "print (\"finished predicting probabilities\")\n",
    "y = data.iloc[0:2500,6]\n",
    "y_pred = res[0:2500]\n",
    "print (evaluate_score (y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save result\n",
    "pd.DataFrame({'id': list(data['id']), 'correctAnswer': res})[['id', 'correctAnswer']].to_csv(\"../predictions/prediction_ck12.csv\", index = False)\n",
    "#pd.DataFrame({'id': list(data['id']),'probA': prob_scores[1:,0],'probB': prob_scores[1:,1],'probC': prob_scores[1:,2],'probD': prob_scores[1:,3]}).to_csv(\"../predictions/prob_prediction_ck12.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
